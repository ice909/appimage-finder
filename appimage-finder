#!/usr/bin/env python3

import argparse
import gzip
import json
import os
import re
import csv
from datetime import datetime, timedelta
from urllib import request
from time import sleep
from collections import defaultdict
import sys
import subprocess

sys.stdout.reconfigure(line_buffering=True)


class CustomHelpFormatter(argparse.RawTextHelpFormatter):
    def _format_usage(self, usage, actions, groups, prefix=None):
        # 完全禁用默认的usage行显示
        return ""


def parse_args():
    parser = argparse.ArgumentParser(
        description=(
            "AppImage Finder\n"
            "从GH Archive数据中查找包含AppImage的GitHub Release，\n"
            "支持按时间筛选（支持年、月、日、小时），自动下载数据，输出JSON或CSV。\n\n"
            "示例用法:\n"
            "  ./appimage-finder --start-time=2025-06-09 --end-time=2025-06-09\n"
            "  ./appimage-finder --start-time=2025-06 --end-time=2025-07 --format=csv --output=result\n"
        ),
        formatter_class=CustomHelpFormatter,
        add_help=False,  # 禁用默认的help选项
    )
    parser.add_argument(
        "-h",
        "--help",
        action="help",
        default=argparse.SUPPRESS,
        help="显示帮助信息并退出",
    )
    parser.add_argument(
        "--start-time",
        required=True,
        help="开始时间，格式支持 yyyy 或 yyyy-mm 或 yyyy-mm-dd 或 yyyy-mm-dd-hh",
    )
    parser.add_argument(
        "--end-time",
        required=True,
        help="结束时间，格式支持 yyyy 或 yyyy-mm 或 yyyy-mm-dd 或 yyyy-mm-dd-hh",
    )
    parser.add_argument(
        "--format",
        choices=["json", "csv"],
        default="json",
        help="输出格式 (json 或 csv)，默认json",
    )
    parser.add_argument(
        "--output", default="appimages", help="输出文件名前缀，默认appimages"
    )
    parser.add_argument(
        "--include-checksums",
        action="store_true",
        help="包含校验和文件 (.sha256sum, .md5 等) 的AppImage",
    )
    parser.add_argument(
        "--keep-all",
        action="store_true",
        help="保留所有版本的AppImage，不仅是最新版本（默认只保留最新）",
    )
    parser.add_argument(
        "--arch",
        choices=["x86_64", "aarch64", "all"],
        default="all",
        help="指定AppImage架构 (x86_64, aarch64, all)，默认all",
    )
    return parser.parse_args()


def extract_architecture(filename):
    """从文件名中提取架构信息"""
    arch_patterns = {
        "x86_64": r"(x86_64|x86-64|amd64|64bit|x64|x86)",
        "aarch64": r"(aarch64|arm64|ARM64)",
    }
    for arch, pattern in arch_patterns.items():
        if re.search(pattern, filename, re.IGNORECASE):
            return arch
    return None


def parse_time_str(tstr):
    parts = tstr.split("-")
    year = int(parts[0])
    month = int(parts[1]) if len(parts) > 1 else None
    day = int(parts[2]) if len(parts) > 2 else None
    hour = int(parts[3]) if len(parts) > 3 else None

    if hour is not None:
        precision = "hour"
        dt = datetime(year, month, day, hour)
    elif day is not None:
        precision = "day"
        dt = datetime(year, month, day)
    elif month is not None:
        precision = "month"
        dt = datetime(year, month, 1)
    else:
        precision = "year"
        dt = datetime(year, 1, 1)

    return dt, precision


def adjust_end_time(dt, precision):
    if precision == "year":
        return datetime(dt.year, 12, 31, 23)
    elif precision == "month":
        if dt.month == 12:
            next_month = datetime(dt.year + 1, 1, 1)
        else:
            next_month = datetime(dt.year, dt.month + 1, 1)
        last_day = (next_month - timedelta(days=1)).day
        return datetime(dt.year, dt.month, last_day, 23)
    elif precision == "day":
        return datetime(dt.year, dt.month, dt.day, 23)
    elif precision == "hour":
        return dt


def generate_hourly_urls(start_dt, end_dt):
    urls = []
    cur = start_dt
    while cur <= end_dt:
        url = f"https://data.gharchive.org/{cur.year}-{cur.month:02d}-{cur.day:02d}-{cur.hour}.json.gz"
        urls.append((url, cur.strftime("%Y-%m-%d-%H.json.gz")))
        cur += timedelta(hours=1)
    return urls


def download_file(url, filename):
    if os.path.exists(filename):
        print(f"文件已存在，跳过下载: {filename}")
        return

    print(f"开始下载: {filename}")

    try:
        # --continue 支持断点续传, --tries=3 尝试3次, --timeout=60 设置超时
        subprocess.run(
            ["wget", "-O", filename, "--continue", "--tries=3", "--timeout=60", url],
            check=True,
            encoding="utf-8",
        )
        print(f"\n下载完成: {filename}")
    except Exception as e:
        print(f"\n下载失败: {filename}  错误: {e}")
        if os.path.exists(filename):
            os.remove(filename)  # 删除损坏的文件


def match_time(event_time, start_dt, end_dt):
    dt = datetime.strptime(event_time, "%Y-%m-%dT%H:%M:%SZ")
    return start_dt <= dt <= end_dt


def extract_version_from_filename(filename):
    match = re.search(r"[-_]?v?(\d+\.\d+(?:\.\d+)*)", filename)
    return match.group(1) if match else None


def is_continuous_release(release_name, appimages):
    keywords = ["continuous", "continous", "latest", "nightly", "daily", "current"]
    if release_name and any(kw in release_name.lower() for kw in keywords):
        return True
    versions = set()
    for asset in appimages:
        version = extract_version_from_filename(asset["name"])
        if version:
            versions.add(version)
    return len(versions) >= 3


def filter_appimages(assets, include_checksums, target_arch):
    filtered = []
    checksum_suffixes = (".sha256sum", ".md5", ".sha256", ".sha512", ".md5sum")

    for asset in assets:
        name = asset["name"]
        if name.endswith(".AppImage"):
            arch = extract_architecture(name)
            if target_arch == "all":
                filtered.append(asset)
            elif arch == target_arch:
                filtered.append(asset)
            elif arch is None and target_arch == "x86_64":
                # 文件名未标注架构，且目标是 x86_64，则认为是 x86_64
                filtered.append(asset)
        elif include_checksums and any(name.endswith(suf) for suf in checksum_suffixes):
            base_name = name.split(".")[0]
            if any(
                a["name"].startswith(base_name) and a["name"].endswith(".AppImage")
                for a in assets
            ):
                filtered.append(asset)
    return filtered


def keep_latest_versions(results):
    latest = {}
    for item in results:
        # key 变成 (repo, architecture)
        key = (item["repo"], item["architecture"])
        if key not in latest or datetime.strptime(
            item["published_at"], "%Y-%m-%dT%H:%M:%SZ"
        ) > datetime.strptime(latest[key]["published_at"], "%Y-%m-%dT%H:%M:%SZ"):
            latest[key] = item
    return list(latest.values())

def extract_version_4digit(tag, filename):
    # 尝试从 tag 或文件名里提取形如1.2.3.4、1.2.3、1.2等
    for s in [tag, filename]:
        if not s:
            continue
        m = re.search(r"(\d+)\.(\d+)\.(\d+)(?:\.(\d+))?", s)
        if m:
            parts = [int(p) if p else 0 for p in m.groups()]
            while len(parts) < 4:
                parts.append(0)
            return ".".join(str(x) for x in parts[:4])
    return "1.0.0.0"


def get_package_name(repo):
    # io.github.owner.repo，全部小写
    owner, repo_name = repo.lower().split("/", 1)
    return f"io.github.{owner}.{repo_name}"


def process_file(
    filepath, start_dt, end_dt, include_checksums, keep_all, target_arch, results
):
    with gzip.open(filepath, "rt", encoding="utf-8") as f:
        for line in f:
            event = json.loads(line)
            if event.get("type") != "ReleaseEvent":
                continue
            if not match_time(event["created_at"], start_dt, end_dt):
                continue
            release = event["payload"].get("release")
            if not release or not release.get("assets"):
                continue
            appimages = filter_appimages(
                release["assets"], include_checksums, target_arch
            )
            if not appimages:
                continue
            if is_continuous_release(release.get("name", ""), appimages):
                continue
            for asset in appimages:
                arch = extract_architecture(asset["name"])
                if (target_arch == "all" or target_arch == "x86_64") and arch is None:
                    arch = "x86_64"  # 默认认为未标注架构的为 x86_64
                version = extract_version_4digit(release.get("tag_name"), asset["name"])
                package_name = get_package_name(event["repo"]["name"])
                results.append(
                    {
                        "repo": event["repo"]["name"],
                        "release_name": release.get("name"),
                        "tag_name": release.get("tag_name"),
                        "published_at": release.get("published_at"),
                        "appimage_name": asset["name"],
                        "download_url": asset["browser_download_url"],
                        "architecture": arch,
                        "package_name": package_name,
                        "version": version,
                    }
                )
    if not keep_all:
        # 只保留最新版本
        results[:] = keep_latest_versions(results)


def main():
    args = parse_args()
    start_dt, start_prec = parse_time_str(args.start_time)
    end_dt, end_prec = parse_time_str(args.end_time)
    end_dt = adjust_end_time(end_dt, end_prec)

    urls = generate_hourly_urls(start_dt, end_dt)
    os.makedirs("gharchive_tmp", exist_ok=True)

    results = []

    for url, filename in urls:
        local_path = os.path.join("gharchive_tmp", filename)
        download_file(url, local_path)
        if os.path.exists(local_path):
            process_file(
                local_path,
                start_dt,
                end_dt,
                args.include_checksums,
                args.keep_all,
                args.arch,
                results,
            )
        sleep(0.2)  # 防止请求过快

    if not results:
        print("未发现任何有效的 AppImage 发布项。")
        return

    if args.arch == "all":
        # 按架构分组
        arch_groups = defaultdict(list)
        for item in results:
            arch = item["architecture"] or "unknown"
            arch_groups[arch].append(item)
        for arch, group in arch_groups.items():
            if args.format == "json":
                with open(f"{args.output}-{arch}.json", "w", encoding="utf-8") as f:
                    json.dump(group, f, ensure_ascii=False, indent=2)
            else:
                with open(
                    f"{args.output}-{arch}.csv", "w", encoding="utf-8", newline=""
                ) as f:
                    writer = csv.DictWriter(f, fieldnames=group[0].keys())
                    writer.writeheader()
                    writer.writerows(group)
        print(
            f"共发现 {len(results)} 个有效 AppImage 发布项，结果已按架构分别保存为 {args.output}-<arch>.{args.format}"
        )
    else:
        # 单一架构
        if args.format == "json":
            with open(f"{args.output}-{args.arch}.json", "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
        else:
            with open(
                f"{args.output}-{args.arch}.csv", "w", encoding="utf-8", newline=""
            ) as f:
                writer = csv.DictWriter(f, fieldnames=results[0].keys())
                writer.writeheader()
                writer.writerows(results)
        print(
            f"共发现 {len(results)} 个有效 AppImage 发布项，结果已保存为 {args.output}-{args.arch}.{args.format}"
        )


if __name__ == "__main__":
    main()
